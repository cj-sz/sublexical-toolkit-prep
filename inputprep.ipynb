{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Prep\n",
    "\n",
    "This notebook prepares the CMU Dictionary for input into the Sublexical Toolkit for analysis.\n",
    "\n",
    "Author: Caleb Solomon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import cambridge_parser as parser\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Initialize the CMU Dictionary and trim it.\n",
    "\n",
    "The first many lines of the dictionary file are useless, containing simple text. There are also a significant number of words containing numbers, parentheses, or other features that are unnecessary for input to the sublexical toolkit. Furthermore, we want to keep only words whose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ";;; # CMUdict  --  Major Version: 0.07\n",
      ";;;\n",
      ";;; # $HeadURL$\n",
      ";;; # $Date::                                                   $:\n",
      ";;; # $Id::                                                     $:\n",
      ";;; # $Rev::                                                    $:\n",
      ";;; # $Author::                                                 $:\n",
      ";;;\n",
      ";;; #\n",
      ";;; # ========================================================================\n",
      ";;; # Copyright (C) 1993-2015 Carnegie Mellon University. All rights reserved.\n",
      ";;; #\n",
      ";;; # Redistribution and use in source and binary forms, with or without\n",
      ";;; # modification, are permitted provided that the following conditions\n",
      ";;; # are met:\n",
      ";;; #\n",
      ";;; # 1. Redistributions of source code must retain the above copyright\n",
      ";;; #    notice, this list of conditions and the following disclaimer.\n",
      ";;; #    The contents of this file are deemed to be source code.\n",
      ";;; #\n"
     ]
    }
   ],
   "source": [
    "# Display the first 50 or so lines for reference to above.\n",
    "fcmu = open('cmudict-0.7b-2024-4-6.txt')\n",
    "for line in fcmu.readlines()[:20]:\n",
    "    print(line.strip())\n",
    "fcmu.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block takes ~1 min to run.\n",
    "# Create a list of words to pronunciations. Duplicates allowed to introduce alternate pronunciations.\n",
    "# List[(str, str)] duplicates allowed (word, cmu pronunciation)\n",
    "cmu_dict = []\n",
    "\n",
    "# Import the SUBTLEXUS csv to a pandas dataframe.\n",
    "subtlexus = pd.read_csv('SUBTLEXusExcel2007.csv')\n",
    "\n",
    "# Convert all words to lowercase\n",
    "subtlexus['Word'] = subtlexus['Word'].str.lower()\n",
    "\n",
    "# Regex for finding alternate pronunciations of words (which are structured as\n",
    "# \"word(int)\")\n",
    "ralt = r\"(\\w+)\\(\\d+\\)\"\n",
    "\n",
    "# Regex for finding unwanted punctuation in words (essentially any non-word)\n",
    "rpunc = r\".*(\\W|\\d).*\"\n",
    "# Regex for three-peated characters (any word with three or more of the same\n",
    "# letter in a row should be omitted, as none are valid English words for the\n",
    "# purposes of the toolkit)\n",
    "rpeat = r\".*(.)\\1\\1.*\"\n",
    "\n",
    "altpronsct = 0\n",
    "\n",
    "# Iterate through the lines of the dictionary. Add only such words containing\n",
    "# no parentheses and with a corresponding entry in the SUBTLEXUS to the\n",
    "# dictionary of cmu words that will be kept for analysis.\n",
    "with open('cmudict-0.7b-2024-4-6.txt') as file:\n",
    "    # Skip the first 56 lines as these contain text we are not interested in\n",
    "    for line in file.readlines()[56:]:\n",
    "        word, pronunciation = line.strip().split(maxsplit=1)\n",
    "        word = word.lower()\n",
    "        alt = re.match(ralt, word)\n",
    "\n",
    "        # First check if this is an alt pronunciation for a word\n",
    "        if alt is not None:\n",
    "            alt_text = alt.group(1)\n",
    "            # The do the checks on the root\n",
    "            if re.match(rpeat, alt_text) is None \\\n",
    "                and alt_text in subtlexus['Word'].values \\\n",
    "                and re.match(rpunc, alt_text) is None:\n",
    "                cmu_dict.append((alt_text, pronunciation))\n",
    "                altpronsct += 1 # Keep track of num alts\n",
    "        else:\n",
    "            # Otherwise just check general critera\n",
    "            if re.match(rpeat, word) is None \\\n",
    "                and re.match(rpunc, word) is None \\\n",
    "                and word in subtlexus['Word'].values:\n",
    "                cmu_dict.append((word, pronunciation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53388\n",
      "5035\n"
     ]
    }
   ],
   "source": [
    "# Display the final number of words in the dataset\n",
    "print(len(cmu_dict))\n",
    "# Check how many alternate pronunciations appeared\n",
    "print(altpronsct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Cross-reference CMU Dictionary Pronunciations with Cambridge Prounciations\n",
    "\n",
    "First, the CMU dictionary pronunciations will need to be converted to reflect the Cambridge dictionary pronunciation format. The transcriptions csv aids in these conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a list of all possible transcriptions of a cmu word in IPA\n",
    "# form recursively.\n",
    "def possible_transcriptions(cmu_word, replacements):\n",
    "    def helper(index, current_transcription):\n",
    "        # If we are at the end of the word, return the constructed result\n",
    "        if index >= len(cmu_word):\n",
    "            transcriptions.append(current_transcription)\n",
    "            return\n",
    "\n",
    "        # Grab the current phoneme by checking to see if we are at the last\n",
    "        # phoneme (end of the word) or the next whitespace\n",
    "        pend = cmu_word[index:].find(\" \")\n",
    "        if pend != -1:\n",
    "            phoneme = cmu_word[index:index + pend]\n",
    "        else:\n",
    "            phoneme = cmu_word[index:]\n",
    "            pend = len(cmu_word)\n",
    "\n",
    "        # Determine if this is a phoneme that is sensitive to the number at the\n",
    "        # end (i.e. AH0 is differentiated from AH1)\n",
    "        m = re.match(r\"(\\w+)\\d+\", phoneme)\n",
    "        \n",
    "        # If it isn't, remove the number for consideration\n",
    "        if m != None and m.group(1) != \"AH\":\n",
    "            phoneme = m.group(1)\n",
    "\n",
    "        # Recursively generate all possible combinations of phonemes\n",
    "        if phoneme in replacements:\n",
    "            for option in replacements[phoneme]:\n",
    "                helper(index + pend + 1, current_transcription + option)\n",
    "        else:\n",
    "            helper(index + pend + 1, current_transcription + phoneme)\n",
    "\n",
    "    # Call for the word\n",
    "    transcriptions = []\n",
    "    helper(0, \"\")\n",
    "\n",
    "    # Remove all whitespace and extra numbers from the resultant transcription\n",
    "    for t in transcriptions:\n",
    "        t = t.replace(\" \", \"\")\n",
    "        t = re.sub(r\"\\d\", \"\", t)\n",
    "\n",
    "    return transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Word                         Pronunciation\n",
      "0         a                                   [ə]\n",
      "1         a                                  [eɪ]\n",
      "2        aa                                [eɪeɪ]\n",
      "3       aah                                [ɑ, ɒ]\n",
      "4  aardvark  [ɑɹdvɑɹk, ɑɹdvɒɹk, ɒɹdvɑɹk, ɒɹdvɒɹk]\n"
     ]
    }
   ],
   "source": [
    "# Load the transcriptions csv\n",
    "transcriptions = pd.read_csv('transcriptions/transcriptions.csv')\n",
    "\n",
    "# Convert the cmu_dict dictionary to a pandas dataframe\n",
    "cmu_df = pd.DataFrame(cmu_dict, columns=['Word', 'Pronunciation'])\n",
    "\n",
    "# Iterate through the transcriptions and generate a dict of transcriptions\n",
    "# There are two special cases: ER and AA, where each have two different\n",
    "# representation possibilities. These cases need to be handled separately.\n",
    "# Furthermore, sometimes \"AA\" is followed by a number of the format \"AAn\". In\n",
    "# such cases we ignore the number and just replace as AA. To do so after we \n",
    "# apply all pronunciation transcriptions we just remove the remaining numbers\n",
    "# from the transcription. This is done below.\n",
    "replacements = {}  # Dict{str : [str]}\n",
    "special_replacements_ER = [\"ɝ\", \"ɚ\"]\n",
    "special_replacements_AA = [\"ɑ\", \"ɒ\"]\n",
    "\n",
    "for index, row in transcriptions.iterrows():\n",
    "    cmu_p = row['CMU']\n",
    "    ipa_p = row['IPA']\n",
    "\n",
    "    # Skip the special cases where the CMU pronunciation is \"ER\" or \"AA\"\n",
    "    if cmu_p == \"ER\" or cmu_p == \"AA\":\n",
    "        continue\n",
    "    \n",
    "    # Add the IPA representation transcription to the dictionary\n",
    "    replacements[cmu_p] = [ipa_p]\n",
    "\n",
    "replacements[\"ER\"] = special_replacements_ER\n",
    "replacements[\"AA\"] = special_replacements_AA\n",
    "\n",
    "# Iterate through the cmu_dict dictionary and replace all CMU pronunciations\n",
    "# with a list of all possible corresponding pronunciation transcriptions in\n",
    "# IPA.\n",
    "for index, row in cmu_df.iterrows():\n",
    "    ts = possible_transcriptions(row['Pronunciation'], replacements)\n",
    "\n",
    "    cmu_df.at[index, 'Pronunciation'] = ts\n",
    "\n",
    "# Observe some of the results\n",
    "print(cmu_df[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another special case we want to handle for consistency, after we produce all of the IPA pronunciations, we want to make sure all of the \"un\"s are stressed (for example, words like \"undo\" or \"understanding\") (becuase this is the convention the Toolkit has taken). The CMU dictionary uses the unstressed version, so we will just have to check for all words that start with \"un\" and whose corresponding pronunciation starts with \"ə\" and replace the \"ə\" with a \"ʌ\" to indicate stressed in the IPA representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in cmu_df.iterrows():\n",
    "    # Check if the first two characters are \"un\"\n",
    "    if row['Word'][:2] == \"un\":\n",
    "        newps = []\n",
    "        for p in row['Pronunciation']:\n",
    "            if p[0] == \"ə\":\n",
    "                newps.append(\"ʌ\" + p[1:])\n",
    "        row['Pronunciation'] = newps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all CMU dictionary pronunciations have been updated to IPA format, we go through the pronunciations obtained from the Cambridge dictionary and compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE: read in cambridge_ipas which is now a df with four columns:\n",
    "# DFof str str int int\n",
    "# with: str: word \n",
    "#       str: space-separated pronunciation list\n",
    "#       int: root word returned (if we searched for a conjugation)? 0 no 1 yes\n",
    "#       int: missing from cambridge dictionary? 0 no 1 yes\n",
    "\n",
    "# Now, cmu df is a df of int str List[str]\n",
    "# So our final df should be:\n",
    "# cmu_word cmu_ipas cam_ipas match_pron*_ipa match_pron*_toolkit (cmuipa, cambipa) alt_pron? cambridge_root_returned missing_from_cambrdige present_and_discrepant\n",
    "# Dfof str List[str] List[str] List[str] List[str] List[(int, int)] int int int\n",
    "# all ints are 1 true 0 false\n",
    "# something is discrepant if the matched pronunciations are empty\n",
    "# with: str: cmu word\n",
    "#       List[str]: list of possible pronunciations of the cmu word in ipa format \n",
    "#       List[str]: list (possibly empty) of pronunciations for the word returned by cambridge\n",
    "#       List[str]: list (possibly empty) of matched pronunciations, in ipa format \n",
    "#       List[str]: list (possibly empty) of the same matched prons in toolkit format \n",
    "#       List[(int, int)]: list of 1-indexed tuples corresponding to the matched* pronunciations (cmu, cambridge)\n",
    "#       int: was this cmu word an alternate pronunciation? for example, is this the second valid entry in the dictionary for a word?\n",
    "#       int: were the pronunciations from cambridge given as the pronunciations from the root of this word as opposed to the word (likely a conjugate) itself?\n",
    "#       int: was this word completely missing from the cambridge dictionary?\n",
    "\n",
    "# Read in the file, cambridge_ipas.csv, containing all Cambridge words and their potential (space-separated) pronunciations.\n",
    "cambridge_ipas = pd.read_csv(\"cambridge_ipas.csv\")\n",
    "\n",
    "# Convert all of the pronunciations, which are currently space-separated words, into a list of such words\n",
    "for index, row in cambridge_ipas.iterrows():\n",
    "    if isinstance(row['Pronunciation'], str):\n",
    "        cambridge_ipas.at[index, 'Pronunciation'] = row['Pronunciation'].split()\n",
    "    else:\n",
    "        cambridge_ipas.at[index, 'Pronunciation'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cambridge_ipas.loc[cambridge_ipas['Word'] == \"abacus\", 'Root Word Returned'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: This cell takes a few minutes to run!\n",
    "\n",
    "# Initialize the final data frame\n",
    "df = pd.DataFrame(columns=['CMU Word', 'CMU IPAs', 'Cambridge IPAs', 'Matched Pronunciations (IPA)', 'Matched Pronunciations (Toolkit)', 'Pronunciation Matches', 'Alternate Pronunciation', 'Root From Cambridge', 'Missing From Cambridge'])\n",
    "\n",
    "prev_word = \"\"\n",
    "# Iterate through all words in cmu_df.\n",
    "for index, row in cmu_df.iterrows():\n",
    "    # Initialize the row and grab the current word\n",
    "    cmu_word = row['Word']\n",
    "    new_row = {\n",
    "        'CMU Word': cmu_word,\n",
    "        'CMU IPAs': row['Pronunciation'],\n",
    "        'Cambridge IPAs': [],\n",
    "        'Matched Pronunciations (IPA)': [],\n",
    "        'Matched Pronunciations (Toolkit)': [],\n",
    "        'Pronunciation Matches': [],\n",
    "        'Alternate Pronunciation': 0,\n",
    "        'Root From Cambridge': 0,\n",
    "        'Missing From Cambridge': 0\n",
    "    }\n",
    "\n",
    "    # First check if the word was not present in cambridge\n",
    "    if cmu_word not in cambridge_ipas['Word'].values or cambridge_ipas.loc[cambridge_ipas['Word'] == cmu_word, 'Missing'].iloc[0] == 1:\n",
    "        new_row['Missing From Cambridge'] = 1\n",
    "        df.loc[len(df)] = new_row\n",
    "        prev_word = cmu_word\n",
    "        continue\n",
    "    \n",
    "    # Check if it is the root word that was returned\n",
    "    # At this point we know the cmu word exists in cambridge\n",
    "    new_row['Root From Cambridge'] = cambridge_ipas.loc[cambridge_ipas['Word'] == cmu_word, 'Root Word Returned'].iloc[0]\n",
    "    # Check if it is an alternate pronunciation\n",
    "    if prev_word == cmu_word:\n",
    "        new_row['Alternate Pronunciation'] = 1\n",
    "        df.at[df.index[-1], 'Alternate Pronunciation'] = 1\n",
    "    else:\n",
    "        new_row['Alternate Pronunciation'] = 0\n",
    "\n",
    "    # Next grab all the pronunciations from cambridge_ipas and pairwise compare\n",
    "    new_row['Cambridge IPAs'] = cambridge_ipas.loc[cambridge_ipas['Word'] == cmu_word, 'Pronunciation'].iloc[0]\n",
    "    match_list = []\n",
    "    tuple_matches = []\n",
    "    for i, cmu_ipa in enumerate(new_row['CMU IPAs']):\n",
    "        for j, camb_ipa in enumerate(new_row['Cambridge IPAs']):\n",
    "            if cmu_ipa == camb_ipa:\n",
    "                match_list.append(cmu_ipa)\n",
    "                tuple_matches.append((i + 1, j + 1))\n",
    "    new_row['Matched Pronunciations (IPA)'] = match_list\n",
    "    new_row['Pronunciation Matches'] = tuple_matches\n",
    "\n",
    "    # Append the row\n",
    "    df.loc[len(df)] = new_row\n",
    "\n",
    "    # Finally set the new previous word for the purpose of checking alt prons\n",
    "    prev_word = cmu_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO speedup and progress bar \n",
    "# Now, for all words in the result, we want to get the Toolkit transcription as well\n",
    "tdf = pd.read_csv(\"transcriptions/transcriptions.csv\")\n",
    "t_dict = dict(zip(tdf['IPA'], tdf['Toolkit']))\n",
    "t_dict.pop(\"ɝ or ɚ\")\n",
    "t_dict.pop(\"ɑ~ɒ\")\n",
    "t_dict[\"ɑ\"] = \"a\"\n",
    "t_dict[\"ɒ\"] = \"a\"\n",
    "t_dict[\"ɚ\"] = \"3r\"\n",
    "t_dict[\"ɝ\"] = \"3r\"\n",
    "\n",
    "# need to also add eɪ -> 8 because this shows up sometimes\n",
    "_long = [[(\"eɪ\", \"8\")]]\n",
    "# first make a list of tuples of all of the two-character transcriptions\n",
    "for k, v in t_dict.items():\n",
    "    if len(k) >= 2:\n",
    "        _long.append((k, v))\n",
    "\n",
    "# Define a function for transcription\n",
    "def toolkit_transcribe(p):\n",
    "    tp = \"\"\n",
    "    i = 0\n",
    "    while i < len(p):\n",
    "        found = False\n",
    "        if i < len(p) - 1:\n",
    "            for lt in _long:\n",
    "                if p[i:i+2] == lt[0]:\n",
    "                    tp += lt[1]\n",
    "                    i += 2\n",
    "                    found = True\n",
    "                    break\n",
    "        if not found:\n",
    "            try:\n",
    "                tp += t_dict[p[i]]\n",
    "            except KeyError:\n",
    "                return \"\"\n",
    "            i += 1\n",
    "    return tp\n",
    "\n",
    "# Add empty columns for \"CMU (Toolkit)\" and \"Cambridge (Toolkit)\"\n",
    "# df.insert(3, 'CMU (Toolkit)', '')\n",
    "# df.insert(4, 'Cambridge (Toolkit)', '')\n",
    "\n",
    "# Cambridge transcriptions need fixing TODO check cmu_ipa_cambridge\n",
    "\n",
    "# Transcribe matched pronunciations\n",
    "for index, row in df.iterrows():\n",
    "    matched_ps = row['Matched Pronunciations (IPA)']\n",
    "    toolkit_ps = list(set([toolkit_transcribe(p) for p in matched_ps]))\n",
    "    df.at[index, 'Matched Pronunciations (Toolkit)'] = toolkit_ps\n",
    "\n",
    "# Create two new columns for transcription of just the cmu words and just the cambridge words\n",
    "# NEEDS TO BE DOUBLE CHECKED NEXT TIME IS RUN \n",
    "transcribed_cmu = [list(set([toolkit_transcribe(p) for p in row['CMU IPAs']])) for index, row in df.iterrows()]\n",
    "transcribed_cambridge = [list(set([toolkit_transcribe(p) for p in row['Cambridge IPAs']])) for index, row in df.iterrows()]\n",
    "\n",
    "df['CMU (Toolkit)'] = transcribed_cmu\n",
    "df['Cambridge (Toolkit)'] = transcribed_cambridge\n",
    "\n",
    "\n",
    "# TODO: remove this after fixing the Root Returned indicator\n",
    "# currently rerunning \n",
    "# Note sometimes root says returned if something worked but isn't exact\n",
    "# like abc -> ABC ret \n",
    "# df = df.drop('Root From Cambridge', axis=1)\n",
    "\n",
    "# Output to a csv\n",
    "df.to_csv('cmu_ipa_cambridge.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 53388\n",
      "Words missing from Cambridge: 8248\n",
      "Root words returned from Cambridge: 15960\n",
      "Words present in both dictionaries but with no pronunciation matches: 22893\n",
      "Alternate valid pronunciations present: 8475\n"
     ]
    }
   ],
   "source": [
    "# We can then grab some interesting statistics\n",
    "# Total number of entries \n",
    "print(f\"Total words: {len(df)}\")\n",
    "# Number of missing words (there might be a decent amount of junk here)\n",
    "print(f\"Words missing from Cambridge: {df['Missing From Cambridge'].value_counts()[1]}\")\n",
    "# Root words returned\n",
    "print(f\"Root words returned from Cambridge: {df['Root From Cambridge'].value_counts()[1]}\")\n",
    "# Number of discrepant words\n",
    "def discrepant(row):\n",
    "    # Check if the columns are already lists\n",
    "    cm = row['Cambridge IPAs']\n",
    "    mp = row['Matched Pronunciations (IPA)']\n",
    "    \n",
    "    # Parse the string representation of lists if they are not already lists\n",
    "    if isinstance(cm, str):\n",
    "        cm = ast.literal_eval(cm)\n",
    "    if isinstance(mp, str):\n",
    "        mp = ast.literal_eval(mp)\n",
    "    return len(cm) > 0 and len(mp) == 0\n",
    "print(f\"Words present in both dictionaries but with no pronunciation matches: {df.apply(discrepant, axis=1).sum()}\")\n",
    "# Number of alternate pronunciations present\n",
    "print(f\"Alternate valid pronunciations present: {df['Alternate Pronunciation'].value_counts()[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
