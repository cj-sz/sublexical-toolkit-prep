{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Prep\n",
    "\n",
    "This notebook prepares the CMU Dictionary for input into the Sublexical Toolkit for analysis.\n",
    "\n",
    "Author: Caleb Solomon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import cambridge_parser as parser\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Initialize the CMU Dictionary and trim it.\n",
    "\n",
    "The first many lines of the dictionary file are useless, containing simple text. There are also a significant number of words containing numbers, parentheses, or other features that are unnecessary for input to the sublexical toolkit. Furthermore, we want to keep only words whose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ";;; # CMUdict  --  Major Version: 0.07\n",
      ";;;\n",
      ";;; # $HeadURL$\n",
      ";;; # $Date::                                                   $:\n",
      ";;; # $Id::                                                     $:\n",
      ";;; # $Rev::                                                    $:\n",
      ";;; # $Author::                                                 $:\n",
      ";;;\n",
      ";;; #\n",
      ";;; # ========================================================================\n",
      ";;; # Copyright (C) 1993-2015 Carnegie Mellon University. All rights reserved.\n",
      ";;; #\n",
      ";;; # Redistribution and use in source and binary forms, with or without\n",
      ";;; # modification, are permitted provided that the following conditions\n",
      ";;; # are met:\n",
      ";;; #\n",
      ";;; # 1. Redistributions of source code must retain the above copyright\n",
      ";;; #    notice, this list of conditions and the following disclaimer.\n",
      ";;; #    The contents of this file are deemed to be source code.\n",
      ";;; #\n"
     ]
    }
   ],
   "source": [
    "# Display the first 50 or so lines for reference to above.\n",
    "fcmu = open('cmudict-0.7b-2024-4-6.txt')\n",
    "for line in fcmu.readlines()[:20]:\n",
    "    print(line.strip())\n",
    "fcmu.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block takes ~1 min to run.\n",
    "# Create a dictionary of words to pronunciations.\n",
    "# Dict {str : str}\n",
    "cmu_dict = {}\n",
    "\n",
    "# Import the SUBTLEXUS csv to a pandas dataframe.\n",
    "subtlexus = pd.read_csv('SUBTLEXusExcel2007.csv')\n",
    "\n",
    "# Convert all words to lowercase\n",
    "subtlexus['Word'] = subtlexus['Word'].str.lower()\n",
    "\n",
    "# Regex for finding unwanted punctuation in words (essentially any non-word)\n",
    "rpunc = r\".*(\\W|\\d).*\"\n",
    "# Regex for three-peated characters (any word with three or more of the same\n",
    "# letter in a row should be omitted, as none are valid English words for the\n",
    "# purposes of the toolkit)\n",
    "rpeat = r\".*(.)\\1\\1.*\"\n",
    "\n",
    "# Iterate through the lines of the dictionary. Add only such words containing\n",
    "# no parentheses and with a corresponding entry in the SUBTLEXUS to the\n",
    "# dictionary of cmu words that will be kept for analysis.\n",
    "with open('cmudict-0.7b-2024-4-6.txt') as file:\n",
    "    # Skip the first 56 lines as these contain text we are not interested in\n",
    "    for line in file.readlines()[56:]:\n",
    "        word, pronunciation = line.strip().split(maxsplit=1)\n",
    "        word = word.lower()\n",
    "        # Ensure the word doesn't contain punctuation and is present in the\n",
    "        # SUBTLEXUS\n",
    "        if re.match(rpunc, word) is None \\\n",
    "            and re.match(rpeat, word) is None \\\n",
    "            and word in subtlexus['Word'].values:\n",
    "            cmu_dict[word] = pronunciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48353"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the final number of words in the dataset\n",
    "len(cmu_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Cross-reference CMU Dictionary Pronunciations with Cambridge Prounciations\n",
    "\n",
    "First, the CMU dictionary pronunciations will need to be converted to reflect the Cambridge dictionary pronunciation format. The transcriptions csv aids in these conversions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a list of all possible transcriptions of a cmu word in IPA\n",
    "# form recursively.\n",
    "def possible_transcriptions(cmu_word, replacements):\n",
    "    def helper(index, current_transcription):\n",
    "        # If we are at the end of the word, return the constructed result\n",
    "        if index >= len(cmu_word):\n",
    "            transcriptions.append(current_transcription)\n",
    "            return\n",
    "\n",
    "        # Grab the current phoneme by checking to see if we are at the last\n",
    "        # phoneme (end of the word) or the next whitespace\n",
    "        pend = cmu_word[index:].find(\" \")\n",
    "        if pend != -1:\n",
    "            phoneme = cmu_word[index:index + pend]\n",
    "        else:\n",
    "            phoneme = cmu_word[index:]\n",
    "            pend = len(cmu_word)\n",
    "\n",
    "        # Determine if this is a phoneme that is sensitive to the number at the\n",
    "        # end (i.e. AH0 is differentiated from AH1)\n",
    "        m = re.match(r\"(\\w+)\\d+\", phoneme)\n",
    "        \n",
    "        # If it isn't, remove the number for consideration\n",
    "        if m != None and m.group(1) != \"AH\":\n",
    "            phoneme = m.group(1)\n",
    "\n",
    "        # Recursively generate all possible combinations of phonemes\n",
    "        if phoneme in replacements:\n",
    "            for option in replacements[phoneme]:\n",
    "                helper(index + pend + 1, current_transcription + option)\n",
    "        else:\n",
    "            helper(index + pend + 1, current_transcription + phoneme)\n",
    "\n",
    "    # Call for the word\n",
    "    transcriptions = []\n",
    "    helper(0, \"\")\n",
    "\n",
    "    # Remove all whitespace and extra numbers from the resultant transcription\n",
    "    for t in transcriptions:\n",
    "        t = t.replace(\" \", \"\")\n",
    "        t = re.sub(r\"\\d\", \"\", t)\n",
    "\n",
    "    return transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Word                         Pronunciation\n",
      "0         a                                   [ə]\n",
      "1        aa                                [eɪeɪ]\n",
      "2       aah                                [ɑ, ɒ]\n",
      "3  aardvark  [ɑɹdvɑɹk, ɑɹdvɒɹk, ɒɹdvɑɹk, ɒɹdvɒɹk]\n",
      "4     aargh                            [ɑɹɡ, ɒɹɡ]\n"
     ]
    }
   ],
   "source": [
    "# Load the transcriptions csv\n",
    "transcriptions = pd.read_csv('transcriptions/transcriptions.csv')\n",
    "\n",
    "# Convert the cmu_dict dictionary to a pandas dataframe\n",
    "cmu_df = pd.DataFrame(list(cmu_dict.items()), columns=['Word', 'Pronunciation'])\n",
    "\n",
    "# Iterate through the transcriptions and generate a dict of transcriptions\n",
    "# There are two special cases: ER and AA, where each have two different\n",
    "# representation possibilities. These cases need to be handled separately.\n",
    "# Furthermore, sometimes \"AA\" is followed by a number of the format \"AAn\". In\n",
    "# such cases we ignore the number and just replace as AA. To do so after we \n",
    "# apply all pronunciation transcriptions we just remove the remaining numbers\n",
    "# from the transcription. This is done below.\n",
    "replacements = {}  # Dict{str : [str]}\n",
    "special_replacements_ER = [\"ɝ\", \"ɚ\"]\n",
    "special_replacements_AA = [\"ɑ\", \"ɒ\"]\n",
    "\n",
    "for index, row in transcriptions.iterrows():\n",
    "    cmu_p = row['CMU']\n",
    "    ipa_p = row['IPA']\n",
    "\n",
    "    # Skip the special cases where the CMU pronunciation is \"ER\" or \"AA\"\n",
    "    if cmu_p == \"ER\" or cmu_p == \"AA\":\n",
    "        continue\n",
    "    \n",
    "    # Add the IPA representation transcription to the dictionary\n",
    "    replacements[cmu_p] = [ipa_p]\n",
    "\n",
    "replacements[\"ER\"] = special_replacements_ER\n",
    "replacements[\"AA\"] = special_replacements_AA\n",
    "\n",
    "# Iterate through the cmu_dict dictionary and replace all CMU pronunciations\n",
    "# with a list of all possible corresponding pronunciation transcriptions in\n",
    "# IPA.\n",
    "for index, row in cmu_df.iterrows():\n",
    "    ts = possible_transcriptions(row['Pronunciation'], replacements)\n",
    "\n",
    "    cmu_df.at[index, 'Pronunciation'] = ts\n",
    "\n",
    "# Observe some of the results\n",
    "print(cmu_df[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all CMU dictionary pronunciations have been updated to IPA format, we go through the pronunciations obtained from the Cambridge dictionary and compare.\n",
    "\n",
    "First, we write an output file with all of the words in the trimmed CMU dictionary that are not present in the Cambridge dictionary.\n",
    "\n",
    "Then, we load in the words obtained from the Cambridge dictionary and iterate through those, checking against the pronunciation from the CMU dictionary. If there is a corresponding pronunciation in the list of potential Cambridge pronunciations for a given CMU word, we take note of which one it is and mark its number in the list of pronunciations for that word (this will be written to an output file). If there is no corresponding pronunciation in the Cambridge dictionary (i.e. something is potentially amiss with the CMU dictionary pronunciation), we note \"\" as the corresponding pronunciation and indicate a \"0\" for the corresponding pronunciation. In this way we can then keep track of discrepancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the file, cambridge_ipas.csv, containing all Cambridge words and their potential (space-separated) pronunciations.\n",
    "df = pd.read_csv(\"cambridge_ipas.csv\")\n",
    "\n",
    "cambridge_pronunciations = dict(zip(df['Word'], df['Pronunciation']))\n",
    "\n",
    "# Convert all of the pronunciations, which are currently space-separated words, into a list of such words\n",
    "for w, p in cambridge_pronunciations.items():\n",
    "    cambridge_pronunciations[w] = p.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the keys of the cambridge_pronunciations and the cmu entries to see what is missing\n",
    "cmu_dict = dict(zip(cmu_df['Word'], cmu_df['Pronunciation']))\n",
    "\n",
    "missing_dict = {}\n",
    "pop_list = []\n",
    "\n",
    "for w, p in cmu_dict.items():\n",
    "    if w not in cambridge_pronunciations.keys():\n",
    "        missing_dict[w] = ' '.join(p)\n",
    "        pop_list.append(w)\n",
    "\n",
    "final_missing = []\n",
    "\n",
    "for w, p in missing_dict.items():\n",
    "    final_missing.append((w,p))\n",
    "\n",
    "# Remove all of the words not present in Cambridge from the cmu dict list\n",
    "for word in pop_list:\n",
    "    cmu_dict.pop(word)\n",
    "\n",
    "# Output the entries in the trimmed cmu set that are not in the cambridge pronunciation set to a csv.\n",
    "df = pd.DataFrame(final_missing, columns = ['Word', 'Possible Pronunciations'])\n",
    "df.to_csv(\"missing_cmu_words.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that by inspection, a lot of these words don't show up (i.e. words like \"abandoning\") because a search for said word yields the root word (i.e. searching Cambridge for \"abandoning\" yields \"abandon\"). Consequently it may be necessary to go through manually and adjust words like this with said conjugates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we iterate over the words in the CMU and Cambridge dictionaries, checking to see if any\n",
    "# possible pronunciations match. If one does, we take the matching pronunciation from the\n",
    "# Cambridge dictionary, note its number, and append the word, pronunciation, number set to a data frame.\n",
    "# If such a pronunciation does not exist, we append word, \"\", and 0 to the data frame.\n",
    "# This can later be examined to see which CMU words have discrepancies.\n",
    "df = pd.DataFrame(columns = ['Word', 'IPA Pronunciation', 'Cambridge Pronunciation Number'])\n",
    "\n",
    "for cmu_word in cmu_dict.keys():\n",
    "    # Keep track of the corresponding Cambridge pronunciation that is the same and\n",
    "    # its index, if there is one\n",
    "    corresp_p = \"\"\n",
    "    final_index = 0\n",
    "    for p in cmu_dict[cmu_word]:\n",
    "        cambridge_p_index = 0\n",
    "        for camp in cambridge_pronunciations[cmu_word]:\n",
    "            if p == camp and corresp_p == \"\":\n",
    "                # If we haven't yet found a pronunciation and an idex,\n",
    "                # and we just found one, keep track of it and we are done\n",
    "                corresp_p = camp \n",
    "                final_index = cambridge_p_index + 1\n",
    "            cambridge_p_index += 1\n",
    "\n",
    "    # If there is a discrepancy, put in the \n",
    "\n",
    "    # Add whatever results to the data frame\n",
    "    new_row = {'Word': cmu_word, 'IPA Pronunciation': corresp_p, 'Cambridge Pronunciation Number': final_index}\n",
    "    df.loc[len(df)] = new_row\n",
    "\n",
    "# Now, for all words in the result, we want to get the Toolkit transcription as well\n",
    "tdf = pd.read_csv(\"transcriptions/transcriptions.csv\")\n",
    "t_dict = dict(zip(tdf['IPA'], tdf['Toolkit']))\n",
    "t_dict.pop(\"ɝ or ɚ\")\n",
    "t_dict.pop(\"ɑ~ɒ\")\n",
    "t_dict[\"ɑ\"] = \"a\"\n",
    "t_dict[\"ɒ\"] = \"a\"\n",
    "t_dict[\"ɚ\"] = \"3r\"\n",
    "t_dict[\"ɝ\"] = \"3r\"\n",
    "\n",
    "df['Toolkit'] = df['IPA Pronunciation'].apply(lambda x: ''.join(t_dict.get(char, char) for char in x))\n",
    "\n",
    "# Output to a csv\n",
    "df.to_csv('cmu_ipa_cambridge.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of discrepancies: 5546\n"
     ]
    }
   ],
   "source": [
    "# Also print the number of discrepancies present\n",
    "print(f\"Number of discrepancies: {(df['Cambridge Pronunciation Number'] == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['æksɛptɪŋ']\n",
      "['əksɛptɪŋ']\n"
     ]
    }
   ],
   "source": [
    "# Look at accepting as an example\n",
    "print(cmu_dict[\"accepting\"])\n",
    "print(cambridge_pronunciations[\"accepting\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For all of the discrepancies, we made a data frame of the possible IPA transcriptions from\n",
    "# the CMU dictionary as well as all possible pronunciations according to Cambridge\n",
    "disc_df = pd.DataFrame(columns=['Word', 'Possible IPA from CMU', 'Possible IPA from Cambridge'])\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    if row['Cambridge Pronunciation Number'] == 0:\n",
    "        word = row['Word']\n",
    "        new_row = {'Word': word, 'Possible IPA from CMU': \" \".join(cmu_dict[word]), 'Possible IPA from Cambridge': \" \".join(cambridge_pronunciations[word])}\n",
    "        disc_df.loc[len(disc_df)] = new_row\n",
    "\n",
    "disc_df.to_csv(\"discrepancies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
