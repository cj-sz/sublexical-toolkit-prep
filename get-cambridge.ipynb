{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Cambridge Pronunciations\n",
    "\n",
    "This notebook can be run to obtain the cambridge pronunciations, which are output to `cambridge_ipas.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cambridge_parser as parser\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we trim the cmu dictionary based on several criteria. We will then make calls to the Cambridge dictionary for all remaning words to obtain their pronunciations. This cell takes a significant amount of time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell takes a long time to run!\n",
    "wps = {} # str : List[str]\n",
    "\n",
    "with open('cmudict-0.7b-2024-4-6.txt') as file:\n",
    "    # Import the SUBTLEXUS csv to a pandas dataframe.\n",
    "    subtlexus = pd.read_csv('SUBTLEXusExcel2007.csv')\n",
    "\n",
    "    # Convert all words to lowercase\n",
    "    subtlexus['Word'] = subtlexus['Word'].str.lower()\n",
    "\n",
    "    # Regex for finding unwanted punctuation in words (essentially any non-word)\n",
    "    rpunc = r\".*(\\W|\\d).*\"\n",
    "\n",
    "    # Regex for three-peated characters (any word with three or more of the same\n",
    "    # letter in a row should be omitted, as none are valid English words for the\n",
    "    # purposes of the toolkit)\n",
    "    rpeat = r\".*(.)\\1\\1.*\"\n",
    "\n",
    "    l = 56\n",
    "\n",
    "    # Skip the first 56 lines as these contain text we are not interested in\n",
    "    for line in file.readlines()[56:]:\n",
    "        s = line.strip()\n",
    "        i = s.find(\" \", 0)\n",
    "        word = s[:i].lower()\n",
    "        word = word.lower()\n",
    "\n",
    "        # Ensure the word doesn't contain punctuation and is present in the SUBTLEXUS\n",
    "        if re.match(rpunc, word) is None \\\n",
    "            and re.match(rpeat, word) is None \\\n",
    "            and word in subtlexus['Word'].values:\n",
    "            # Add the word to the dict \n",
    "            wps[word] = \"\"\n",
    "\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the number of words whose pronunciations will be obtained from the Cambridge dictionary\n",
    "print(len(wps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, using `cambridge_parser.py` we obtain the pronunciations for all words in the trimmed list.\n",
    "\n",
    "\n",
    "Note that this next cell take an incredibly long time (hours) to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each word in the dict, get its corresponding pronunciation from Cambridge;\n",
    "# if it is not in Cambridge, remove it from the dict \n",
    "\n",
    "wps_keys = list(wps.keys())\n",
    "wps_words = str(len(wps_keys))\n",
    "# Four steps of iteration to prevent errors\n",
    "step = int(len(wps_keys) / 4) # TODO turn the step into a variable\n",
    "stepn = 1\n",
    "wordnum = 1\n",
    "\n",
    "# Iterate through trimmed word list \n",
    "# This is done in several steps to reduce capacity for errors\n",
    "for i in range(0, len(wps_keys), step):\n",
    "    # Temporary dict in which to store words from this iteration\n",
    "    temp_words = {}\n",
    "    words_to_remove = []\n",
    "\n",
    "    # todo dont hardcode 4\n",
    "    print(f\"Stepping through words {wps_keys[i]} to {wps_keys[i + step - 1]} in step {str(stepn)} of 4...\")\n",
    "\n",
    "    for word in wps_keys[i:min(len(wps_keys), i + step)]:\n",
    "        print(f\"Obtaining pronunciations for word {word}; {str(wordnum)} of {wps_words} words...\", end=\"\\r\")\n",
    "\n",
    "        # Grab cambridge information\n",
    "        cword = parser.define(word)\n",
    "\n",
    "        # List of pronunciations for the word in US_IPA in space-separated string\n",
    "        ps = \"\"\n",
    "\n",
    "        # Iterate through all definitions\n",
    "        for defnum in range(len(cword)):\n",
    "            try:\n",
    "                # Obtain all pronunciations and format them correctly\n",
    "                pslist = cword[defnum][word][0]['data']['US_IPA']\n",
    "                for p in pslist:\n",
    "                    # Append the formatted pronunciation to space separated string of pronuns\n",
    "                    ps = ps + \" \" + p[0].replace(\".\",\"\").replace(\"/\",\"\")\n",
    "            # if something times out we can grab it later by hand \n",
    "            except (RuntimeError, KeyError, IndexError, TimeoutError):\n",
    "                # Continue iterating if error occurs; these can be cleaned up manually later\n",
    "                continue \n",
    "\n",
    "        # If there are pronunciations for this word, add them to the dict\n",
    "        if len(ps) != 0:\n",
    "            temp_words[word] = ps\n",
    "\n",
    "        wordnum += 1\n",
    "    # Output the words and pronunciations we have accumulated\n",
    "    print(\"\")\n",
    "    print(\"Finished obtaining pronunciations for this iteration.\")\n",
    "\n",
    "    word_pronunciation_pairs = []\n",
    "\n",
    "    # Iterate through the dictionary and convert it into a list of tuples\n",
    "    for word, pronunciation in temp_words.items():\n",
    "        # Append each word-pronunciation pair as a tuple to the list\n",
    "        word_pronunciation_pairs.append((word, pronunciation))\n",
    "\n",
    "    # Create a DataFrame from the list of tuples\n",
    "    df = pd.DataFrame(word_pronunciation_pairs, columns=['Word', 'Pronunciation'])\n",
    "\n",
    "    # Output the DataFrame to a CSV file\n",
    "    df.to_csv(f\"temp/cambridge_ipas_step{str(stepn)}.csv\", index=False)\n",
    "\n",
    "    print(f\"Output csv for step {str(stepn)} to cambridge_ipas_step{str(stepn)}.csv\")\n",
    "    \n",
    "    stepn += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above loop missed the very last word (\"zygote\") so we grab that manually\n",
    "# This also serves as a direct example of how the words are obtained from the dictionary\n",
    "zy = parser.define(\"zygote\")\n",
    "\n",
    "ps = \"\"\n",
    "\n",
    "for defnum in range(len(zy)):\n",
    "    try:\n",
    "        # Obtain all pronunciations and format them correctly\n",
    "        pslist = zy[defnum]['zygote'][0]['data']['US_IPA']\n",
    "        for p in pslist:\n",
    "            # Append the formatted pronunciation to space separated string of pronuns\n",
    "            ps = ps + \" \" + p[0].replace(\".\",\"\").replace(\"/\",\"\")\n",
    "    # if something times out we can grab it later by hand \n",
    "    except (RuntimeError, KeyError, IndexError, TimeoutError):\n",
    "        # Continue iterating if error occurs; these can be cleaned up manually later\n",
    "        continue \n",
    "\n",
    "zygote_pronunciation_pair = [(\"zygote\", ps)]\n",
    "\n",
    "# Output this to a data frame and then a csv \n",
    "df = pd.DataFrame(zygote_pronunciation_pair, columns = ['Word', 'Pronunciation'])\n",
    "df.to_csv(\"temp/cambridge_ipas_step5.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did the above with separate data frames to minimize the opportunity for error (and thus work lost). Now, re-read the data frames into a dict. We will iterate through this dict to make some final adjustments to the pronunciations and then output the completed result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25455"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty dictionary to hold the combined data\n",
    "all_cambridge_ipas = {}\n",
    "\n",
    "# Iterate over the CSV files\n",
    "for i in range(1, 6):\n",
    "    # Load the data frame from the CSV file\n",
    "    df = pd.read_csv(f'temp/cambridge_ipas_step{i}.csv')\n",
    "    \n",
    "    # Convert the data frame to a dictionary and update the combined dictionary\n",
    "    all_cambridge_ipas.update(dict(zip(df['Word'], df['Pronunciation'])))\n",
    "\n",
    "# Verify the length\n",
    "len(all_cambridge_ipas.keys())\n",
    "\n",
    "# Note this length is very different because even many words in the trimmed dictionary are not present in the Cambridge dictionary! We will get a file of these below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By inspection it also turns out there are several other characters present in many of the pronunciations that are not a part of the actual pronunciation. We remove all of these as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all words in the resultant dictionary.\n",
    "# Remove the following characters: ˈ · ː - ˌ with empty string\n",
    "# Also notice for some reason Cambridge dictionary does not have proper \"r\" as \"ɹ\" so we\n",
    "# replace this too\n",
    "# and \"t̬\" should just be \"t\"\n",
    "# finally, any instance of \"e\" should be replaced with \"ɛ\" so long as it is not followed by an \"ɪ\"\n",
    "# as that corresponds to a different phoneme\n",
    "for w, p in all_cambridge_ipas.items():\n",
    "    all_cambridge_ipas[w] = re.sub(r'e(?!ɪ)', 'ɛ', p.replace(\"ˈ\",\"\").replace(\"·\",\"\").replace(\"ː\",\"\").replace(\"-\",\"\").replace(\"ˌ\",\"\").replace(\",\",\"\").replace(\"r\",\"ɹ\").replace(\"t̬\",\"t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to artificially change the pronunciation for \"a\" by inspection and also add the pronunciation for \"i\"\n",
    "all_cambridge_ipas['a'] = \"ɛɪ\"\n",
    "all_cambridge_ipas['i'] = \"aɪ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, output the result to a csv\n",
    "final_pronunciations = []\n",
    "\n",
    "for w, p in all_cambridge_ipas.items():\n",
    "    final_pronunciations.append((w,p))\n",
    "\n",
    "df = pd.DataFrame(final_pronunciations, columns=['Word', 'Pronunciation'])\n",
    "df.to_csv(\"cambridge_ipas.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
