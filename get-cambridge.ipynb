{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Cambridge Pronunciations\n",
    "\n",
    "This notebook can be run to obtain the cambridge pronunciations, which are output to `cambridge_ipas.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cambridge_parser as parser\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we trim the cmu dictionary based on several criteria. We will then make calls to the Cambridge dictionary for all remaning words to obtain their pronunciations. This cell takes a significant amount of time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell takes a long time to run!\n",
    "wps = {} # str : List[str]\n",
    "\n",
    "with open('cmudict-0.7b-2024-4-6.txt') as file:\n",
    "    # Import the SUBTLEXUS csv to a pandas dataframe.\n",
    "    subtlexus = pd.read_csv('SUBTLEXusExcel2007.csv')\n",
    "\n",
    "    # Convert all words to lowercase\n",
    "    subtlexus['Word'] = subtlexus['Word'].str.lower()\n",
    "\n",
    "    # Regex for finding alternate pronunciations of words (which are structured as\n",
    "    # \"word(int)\")\n",
    "    ralt = r\"\\s\" # TODO finish implementing this \n",
    "\n",
    "    # Regex for finding unwanted punctuation in words (essentially any non-word)\n",
    "    rpunc = r\".*(\\W|\\d).*\"\n",
    "\n",
    "    # Regex for three-peated characters (any word with three or more of the same\n",
    "    # letter in a row should be omitted, as none are valid English words for the\n",
    "    # purposes of the toolkit)\n",
    "    rpeat = r\".*(.)\\1\\1.*\"\n",
    "\n",
    "    l = 56\n",
    "\n",
    "    # Skip the first 56 lines as these contain text we are not interested in\n",
    "    for line in file.readlines()[56:]:\n",
    "        s = line.strip()\n",
    "        i = s.find(\" \", 0)\n",
    "        word = s[:i].lower()\n",
    "        word = word.lower()\n",
    "\n",
    "        # We need to do a check to see if it is an alternate pronunciation.\n",
    "        # If it is, remove the alt. pronunciation tag, and add this to our list\n",
    "        # of words to keep.\n",
    "        \n",
    "\n",
    "        # Ensure the word doesn't contain punctuation and is present in the SUBTLEXUS\n",
    "        if re.match(rpunc, word) is None \\\n",
    "            and re.match(rpeat, word) is None \\\n",
    "            and word in subtlexus['Word'].values:\n",
    "            # Add the word to the dict \n",
    "            wps[word] = \"\"\n",
    "\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48353\n"
     ]
    }
   ],
   "source": [
    "# Show the number of words whose pronunciations will be obtained from the Cambridge dictionary\n",
    "print(len(wps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, using `cambridge_parser.py` we obtain the pronunciations for all words in the trimmed list.\n",
    "\n",
    "\n",
    "Note that this next cell take an incredibly long time (hours) to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stepping through words a to dilatory in step 1 of 4...\n",
      "Obtaining pronunciations for word aa; 2 of 48353 words...\r"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 45\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# Obtain all pronunciations and format them correctly\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# NOTE: here, if word is a conjugate of some other word (for example \"abandoning\" whose\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# in the resultant.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# So check if it is not none if there is an exception and append this instead?\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     pslist \u001b[38;5;241m=\u001b[39m \u001b[43mcword\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdefnum\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUS_IPA\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m pslist:\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;66;03m# Append the formatted pronunciation to space separated string of pronuns\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'aa'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 58\u001b[0m\n\u001b[0;32m     56\u001b[0m         pslist \u001b[38;5;241m=\u001b[39m cword[defnum][k][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUS_IPA\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m pslist:\n\u001b[1;32m---> 58\u001b[0m             ps \u001b[38;5;241m=\u001b[39m ps \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;66;03m# Get all of the possible pronuns from things that are returned\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     root_ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# In this case the word was not there at all \u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# We will append these separately later \u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# For each word in the dict, get its corresponding pronunciation from Cambridge;\n",
    "# if it is not in Cambridge, remove it from the dict \n",
    "\n",
    "wps_keys = list(wps.keys())\n",
    "wps_words = str(len(wps_keys))\n",
    "# Four steps of iteration to prevent errors\n",
    "step = int(len(wps_keys) / 4) # TODO turn the step into a variable\n",
    "stepn = 1\n",
    "wordnum = 1\n",
    "\n",
    "# Iterate through trimmed word list \n",
    "# This is done in several steps to reduce capacity for errors\n",
    "for i in range(0, len(wps_keys), step):\n",
    "    # Temporary dict in which to store words from this iteration\n",
    "    temp_words = {} # [str : [str, int, int]]\n",
    "    words_to_remove = []\n",
    "\n",
    "    # todo dont hardcode 4\n",
    "    print(f\"Stepping through words {wps_keys[i]} to {wps_keys[i + step - 1]} in step {str(stepn)} of 4...\")\n",
    "\n",
    "    for word in wps_keys[i:min(len(wps_keys), i + step)]:\n",
    "        print(f\"Obtaining pronunciations for word {word}; {str(wordnum)} of {wps_words} words...\", end=\"\\r\")\n",
    "\n",
    "        # Grab cambridge information\n",
    "        cword = parser.define(word)\n",
    "\n",
    "        # List of pronunciations for the word in US_IPA in space-separated string\n",
    "        ps = \"\" # If this remains empty by the end then ofc we didnt find the word in the dict so no pronuns.\n",
    "        # Is this the conjugate of some root word? (0 is no, 1 is yes)\n",
    "        # If this is 1 it means that we searched for something like \"abandoning\" and \"abandon\" was returned\n",
    "        # In such a case we still want to keep the pronunciations\n",
    "        root_ret = 0\n",
    "        missing = 0 # 0 if we got something back from cambridge, 1 otherwise (meaning the word is not present at all)\n",
    "\n",
    "        # Iterate through all definitions\n",
    "        for defnum in range(len(cword)):\n",
    "            try:\n",
    "                # Obtain all pronunciations and format them correctly\n",
    "                # NOTE: here, if word is a conjugate of some other word (for example \"abandoning\" whose\n",
    "                # root word is \"abandon\") the returned data from the parser will have \"abandon\" in the\n",
    "                # word position below.\n",
    "                # But, we want to keep words that gave us the root word but not the full pronunciation\n",
    "                # in the resultant.\n",
    "                # So check if it is not none if there is an exception and append this instead?\n",
    "                pslist = cword[defnum][word][0]['data']['US_IPA']\n",
    "                for p in pslist:\n",
    "                    # Append the formatted pronunciation to space separated string of pronuns\n",
    "                    ps = ps + \" \" + p[0].replace(\".\",\"\").replace(\"/\",\"\")\n",
    "            # if something times out we can grab it later by hand \n",
    "            except (RuntimeError, KeyError, IndexError, TimeoutError):\n",
    "                # In this case we might have obtained the root word of the word we tried to search for\n",
    "                # Make sure something was actually returned \n",
    "                if len(cword) != 0:\n",
    "                    # The pronunciations will be available in the first nonempty IPAs set\n",
    "                    for k, v in cword[defnum].items():\n",
    "                        pslist = cword[defnum][k][0]['data']['US_IPA']\n",
    "                        for p in pslist:\n",
    "                            ps = ps + \" \" + p[0].replace(\".\",\"\").replace(\"/\",\"\") # Get all of the possible pronuns from things that are returned\n",
    "                    root_ret = 1\n",
    "                else:\n",
    "                    # In this case the word was not there at all \n",
    "                    # We will append these separately later \n",
    "                    missing = 1\n",
    "                \n",
    "\n",
    "        # If there are pronunciations for this word, add them to the dict\n",
    "        temp_words[word] = [ps, root_ret, missing]\n",
    "        wordnum += 1\n",
    "\n",
    "    # Output the words and pronunciations we have accumulated\n",
    "    print(\"\")\n",
    "    print(\"Finished obtaining pronunciations for this iteration.\")\n",
    "\n",
    "    word_pronunciation_pairs = []\n",
    "\n",
    "    # Iterate through the dictionary and convert it into a list of tuples\n",
    "    for word, data in temp_words.items():\n",
    "        # Break data into pronunciations and whether or not the item was missing (conjugate or entirely)\n",
    "        word_pronunciation_pairs.append((word, data[0], data[1], data[2]))\n",
    "\n",
    "    # Create a DataFrame from the list of tuples\n",
    "    df = pd.DataFrame(word_pronunciation_pairs, columns=['Word', 'Pronunciation', 'Root Word Returned', 'Missing'])\n",
    "\n",
    "    # Output the DataFrame to a CSV file\n",
    "    df.to_csv(f\"temp/cambridge_ipas_step{str(stepn)}.csv\", index=False)\n",
    "\n",
    "    print(f\"Output csv for step {str(stepn)} to cambridge_ipas_step{str(stepn)}.csv\")\n",
    "    \n",
    "    stepn += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This will likely not be the case in the future. Need to 1) adjust above for loop to work in general\n",
    "# case for steps and 2) remodify the cambridge dictionary input list because some things are being trimmed that\n",
    "# might not necessarily want to be (see notes) \n",
    "# The above loop missed the very last word (\"zygote\") so we grab that manually\n",
    "# This also serves as a direct example of how the words are obtained from the dictionary\n",
    "zy = parser.define(\"zygote\")\n",
    "\n",
    "ps = \"\"\n",
    "root_ret = 0\n",
    "missing = 0 # 0 if we got something back from cambridge, 1 otherwise (meaning the word is not present at all)\n",
    "\n",
    "for defnum in range(len(cword)):\n",
    "    try:\n",
    "        # Obtain all pronunciations and format them correctly\n",
    "        # NOTE: here, if word is a conjugate of some other word (for example \"abandoning\" whose\n",
    "        # root word is \"abandon\") the returned data from the parser will have \"abandon\" in the\n",
    "        # word position below.\n",
    "        # But, we want to keep words that gave us the root word but not the full pronunciation\n",
    "        # in the resultant.\n",
    "        # So check if it is not none if there is an exception and append this instead?\n",
    "        pslist = cword[defnum][word][0]['data']['US_IPA']\n",
    "        for p in pslist:\n",
    "            # Append the formatted pronunciation to space separated string of pronuns\n",
    "            ps = ps + \" \" + p[0].replace(\".\",\"\").replace(\"/\",\"\")\n",
    "    # if something times out we can grab it later by hand \n",
    "    except (RuntimeError, KeyError, IndexError, TimeoutError):\n",
    "        # In this case we might have obtained the root word of the word we tried to search for\n",
    "        # Make sure something was actually returned \n",
    "        if len(cword) != 0:\n",
    "            # The pronunciations will be available in the first nonempty IPAs set\n",
    "            for k, v in cword[defnum]:\n",
    "                pslist = cword[defnum][k][0]['data']['US_IPA']\n",
    "                for p in pslist:\n",
    "                    ps = ps + \" \" + p[0].replace(\".\",\"\").replace(\"/\",\"\") # Get all of the possible pronuns from things that are returned\n",
    "            root_ret = 1\n",
    "        else:\n",
    "            # In this case the word was not there at all \n",
    "            # We will append these separately later \n",
    "            missing = 1\n",
    "\n",
    "zygote_pronunciation_tuple = [(\"zygote\", ps, root_ret, missing)]\n",
    "\n",
    "# Output this to a data frame and then a csv \n",
    "df = pd.DataFrame(zygote_pronunciation_tuple, columns = ['Word', 'Pronunciation', 'Root Word Returned', 'Missing'])\n",
    "df.to_csv(\"temp/cambridge_ipas_step5.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did the above with separate data frames to minimize the opportunity for error (and thus work lost). Now, re-read the data frames into a dict. We will iterate through this dict to make some final adjustments to the pronunciations and then output the completed result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25455"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize an empty dictionary to hold the combined data\n",
    "all_cambridge_ipas = {}\n",
    "\n",
    "# Iterate over the CSV files\n",
    "for i in range(1, 6):\n",
    "    # Load the data frame from the CSV file\n",
    "    df = pd.read_csv(f'temp/cambridge_ipas_step{i}.csv')\n",
    "    \n",
    "    # Convert the data frame to a dictionary and update the combined dictionary\n",
    "    all_cambridge_ipas.update(dict(zip(df['Word'], [df['Pronunciation'], df['Root Word Returned'], df['Missing']])))\n",
    "\n",
    "# Verify the length\n",
    "len(all_cambridge_ipas.keys())\n",
    "\n",
    "# Note this length is very different because even many words in the trimmed dictionary are not present in the Cambridge dictionary! We will get a file of these below.\n",
    "# Once done with updates actually this length should be the same "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By inspection it also turns out there are several other characters present in many of the pronunciations that are not a part of the actual pronunciation. We remove all of these as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all words in the resultant dictionary.\n",
    "# Remove the following characters: ˈ · ː - ˌ with empty string\n",
    "# Also notice for some reason Cambridge dictionary does not have proper \"r\" as \"ɹ\" so we\n",
    "# replace this too\n",
    "# and \"t̬\" should just be \"t\"\n",
    "# finally, any instance of \"e\" should be replaced with \"ɛ\" so long as it is not followed by an \"ɪ\"\n",
    "# as that corresponds to a different phoneme\n",
    "for w, data in all_cambridge_ipas.items():\n",
    "    all_cambridge_ipas[w] = re.sub(r'e(?!ɪ)', 'ɛ', data[0].replace(\"ˈ\",\"\").replace(\"·\",\"\").replace(\"ː\",\"\").replace(\"-\",\"\").replace(\"ˌ\",\"\").replace(\",\",\"\").replace(\"r\",\"ɹ\").replace(\"t̬\",\"t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to artificially change the pronunciation for \"a\" by inspection and also add the pronunciation for \"i\"\n",
    "all_cambridge_ipas['a'] = \"ɛɪ\"\n",
    "all_cambridge_ipas['i'] = \"aɪ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, output the result to a csv\n",
    "res = []\n",
    "\n",
    "for w, data in all_cambridge_ipas.items():\n",
    "    res.append((w,data[0], data[1], data[2]))\n",
    "\n",
    "df = pd.DataFrame(res, columns=['Word', 'Pronunciation', 'Root Word Returned', 'Missing'])\n",
    "df.to_csv(\"cambridge_ipas.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
