{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining Cambridge Pronunciations\n",
    "\n",
    "This notebook can be run to obtain the cambridge pronunciations, which are output to `cambridge_ipas.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import cambridge_parser as parser\n",
    "import pandas as pd\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we trim the cmu dictionary based on several criteria. We will then make calls to the Cambridge dictionary for all remaning words to obtain their pronunciations. This cell takes a significant amount of time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell takes upwards of a few minutes to run\n",
    "wps = {} # str : List[str]\n",
    "\n",
    "with open('cmudict-0.7b-2024-4-6.txt') as file:\n",
    "    # Import the SUBTLEXUS csv to a pandas dataframe.\n",
    "    subtlexus = pd.read_csv('SUBTLEXusExcel2007.csv')\n",
    "\n",
    "    # Convert all words to lowercase\n",
    "    subtlexus['Word'] = subtlexus['Word'].str.lower()\n",
    "\n",
    "    # Regex for finding alternate pronunciations of words (which are structured as\n",
    "    # \"word(int)\")\n",
    "    ralt = r\"(\\w+)\\(\\d+\\)\"\n",
    "\n",
    "    # Regex for finding unwanted punctuation in words (essentially any non-word)\n",
    "    rpunc = r\".*(\\W|\\d).*\"\n",
    "\n",
    "    # Regex for three-peated characters (any word with three or more of the same\n",
    "    # letter in a row should be omitted, as none are valid English words for the\n",
    "    # purposes of the toolkit)\n",
    "    rpeat = r\".*(.)\\1\\1.*\"\n",
    "\n",
    "    l = 56\n",
    "\n",
    "    # Skip the first 56 lines as these contain text we are not interested in\n",
    "    for line in file.readlines()[56:]:\n",
    "        s = line.strip()\n",
    "        i = s.find(\" \", 0)\n",
    "        word = s[:i].lower()\n",
    "        word = word.lower()\n",
    "\n",
    "        alt = re.match(ralt, word)\n",
    "\n",
    "        # First check if this is an alt pronunciation for a word\n",
    "        if alt is not None:\n",
    "            alt_text = alt.group(1)\n",
    "            # The do the checks on the root (for robustness)\n",
    "            if re.match(rpeat, alt_text) is None \\\n",
    "                and alt_text in subtlexus['Word'].values \\\n",
    "                and re.match(rpunc, alt_text) is None:\n",
    "                wps[alt_text] = \"\"\n",
    "        else:\n",
    "            # Otherwise just check general critera\n",
    "            if re.match(rpeat, word) is None \\\n",
    "                and re.match(rpunc, word) is None \\\n",
    "                and word in subtlexus['Word'].values:\n",
    "                wps[word] = \"\"\n",
    "\n",
    "        l += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48353\n"
     ]
    }
   ],
   "source": [
    "# Show the number of words whose pronunciations will be obtained from the Cambridge dictionary\n",
    "print(len(wps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, using `cambridge_parser.py` we obtain the pronunciations for all words in the trimmed list.\n",
    "\n",
    "\n",
    "Note that this next cell takes an incredibly long time (hours) to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each word in the dict, get its corresponding pronunciation from Cambridge;\n",
    "# if it is not in Cambridge, remove it from the dict \n",
    "\n",
    "wps_keys = list(wps.keys())\n",
    "wps_words = str(len(wps_keys))\n",
    "stepn = 1\n",
    "wordnum = 1\n",
    "\n",
    "# start the low index at 0\n",
    "low = 0\n",
    "\n",
    "# Do the iteration in four steps to prevent errors\n",
    "for step in range(1, 5):\n",
    "    # Temporary dict in which to store words from this iteration\n",
    "    temp_words = {} # [str : [str, int, int]]\n",
    "\n",
    "    print(f\"Stepping through words {wps_keys[low]} to {wps_keys[min(len(wps_keys), (int)(step * len(wps_keys) / 4)) - 1]} in step {str(step)} of 4...\")\n",
    "\n",
    "    for word in wps_keys[low:min(len(wps_keys), (int)(step * len(wps_keys) / 4))]:\n",
    "        print(f\"Obtaining pronunciations for word {word}; {str(wordnum)} of {wps_words} words...\", end=\"\\r\")\n",
    "\n",
    "        # Grab cambridge information\n",
    "        cword = parser.define(word)\n",
    "\n",
    "        # List of pronunciations for the word in US_IPA in space-separated string\n",
    "        ps = \"\" # If this remains empty by the end then ofc we didnt find the word in the dict so no pronuns.\n",
    "        # Is this the conjugate of some root word? (0 is no, 1 is yes)\n",
    "        # If this is 1 it means that we searched for something like \"abandoning\" and \"abandon\" was returned\n",
    "        # In such a case we still want to keep the pronunciations\n",
    "        root_ret = 0\n",
    "        missing = 0 # 0 if we got something back from cambridge, 1 otherwise (meaning the word is not present at all)\n",
    "\n",
    "        # Iterate through all definitions\n",
    "        for defnum in range(len(cword)):\n",
    "            try:\n",
    "                # Obtain all pronunciations and format them correctly\n",
    "                # NOTE: here, if word is a conjugate of some other word (for example \"abandoning\" whose\n",
    "                # root word is \"abandon\") the returned data from the parser will have \"abandon\" in the\n",
    "                # word position below.\n",
    "                # But, we want to keep words that gave us the root word but not the full pronunciation\n",
    "                # in the resultant.\n",
    "                # So check if it is not none if there is an exception and append this instead?\n",
    "                pslist = cword[defnum][word][0]['data']['US_IPA']\n",
    "                for p in pslist:\n",
    "                    # Append the formatted pronunciation to space separated string of pronuns\n",
    "                    ps = ps + \" \" + p[0].replace(\".\",\"\").replace(\"/\",\"\")\n",
    "            # if something times out we can grab it later by hand \n",
    "            except (RuntimeError, KeyError, IndexError, TimeoutError):\n",
    "                # In this case we might have obtained the root word of the word we tried to search for\n",
    "                # Make sure something was actually returned \n",
    "                if len(cword) != 0:\n",
    "                    # The pronunciations will be available in the first nonempty IPAs set\n",
    "                    for k, v in cword[defnum].items():\n",
    "                        pslist = cword[defnum][k][0]['data']['US_IPA']\n",
    "                        for p in pslist:\n",
    "                            # Have to add this check because sometimes it is just empty\n",
    "                            if len(p) > 0:\n",
    "                                ps = ps + \" \" + p[0].replace(\".\",\"\").replace(\"/\",\"\") # Get all of the possible pronuns from things that are returned\n",
    "                    root_ret = 1\n",
    "                else:\n",
    "                    # In this case the word was not there at all \n",
    "                    # We will append these separately later \n",
    "                    missing = 1\n",
    "                \n",
    "\n",
    "        # If there are pronunciations for this word, add them to the dict\n",
    "        temp_words[word] = [ps, root_ret, missing]\n",
    "        wordnum += 1\n",
    "    \n",
    "    # Output the words and pronunciations we have accumulated\n",
    "    print(\"\")\n",
    "    print(\"Finished obtaining pronunciations for this iteration.\")\n",
    "\n",
    "    word_pronunciation_pairs = []\n",
    "\n",
    "    # Iterate through the dictionary and convert it into a list of tuples\n",
    "    for word, data in temp_words.items():\n",
    "        # Break data into pronunciations and whether or not the item was missing (conjugate or entirely)\n",
    "        word_pronunciation_pairs.append((word, data[0], data[1], data[2]))\n",
    "\n",
    "    # Create a DataFrame from the list of tuples\n",
    "    df = pd.DataFrame(word_pronunciation_pairs, columns=['Word', 'Pronunciation', 'Root Word Returned', 'Missing'])\n",
    "\n",
    "    # Output the DataFrame to a CSV file\n",
    "    df.to_csv(f\"temp/cambridge_ipas_step{str(step)}.csv\", index=False)\n",
    "\n",
    "    print(f\"Output csv for step {str(step)} to cambridge_ipas_step{str(step)}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOTE: this is all commented out because I remodified the old loop but we keep this\n",
    "# # as an example here.\n",
    "# # The above loop missed the very last word (\"zygote\") so we grab that manually\n",
    "# # This also serves as a direct example of how the words are obtained from the dictionary\n",
    "# zy = parser.define(\"zygote\")\n",
    "\n",
    "# ps = \"\"\n",
    "# root_ret = 0\n",
    "# missing = 0 # 0 if we got something back from cambridge, 1 otherwise (meaning the word is not present at all)\n",
    "\n",
    "# for defnum in range(len(cword)):\n",
    "#     try:\n",
    "#         # Obtain all pronunciations and format them correctly\n",
    "#         # NOTE: here, if word is a conjugate of some other word (for example \"abandoning\" whose\n",
    "#         # root word is \"abandon\") the returned data from the parser will have \"abandon\" in the\n",
    "#         # word position below.\n",
    "#         # But, we want to keep words that gave us the root word but not the full pronunciation\n",
    "#         # in the resultant.\n",
    "#         # So check if it is not none if there is an exception and append this instead?\n",
    "#         pslist = cword[defnum][word][0]['data']['US_IPA']\n",
    "#         for p in pslist:\n",
    "#             # Append the formatted pronunciation to space separated string of pronuns\n",
    "#             ps = ps + \" \" + p[0].replace(\".\",\"\").replace(\"/\",\"\")\n",
    "#     # if something times out we can grab it later by hand \n",
    "#     except (RuntimeError, KeyError, IndexError, TimeoutError):\n",
    "#         # In this case we might have obtained the root word of the word we tried to search for\n",
    "#         # Make sure something was actually returned \n",
    "#         if len(cword) != 0:\n",
    "#             # The pronunciations will be available in the first nonempty IPAs set\n",
    "#             for k, v in cword[defnum]:\n",
    "#                 pslist = cword[defnum][k][0]['data']['US_IPA']\n",
    "#                 for p in pslist:\n",
    "#                     ps = ps + \" \" + p[0].replace(\".\",\"\").replace(\"/\",\"\") # Get all of the possible pronuns from things that are returned\n",
    "#             root_ret = 1\n",
    "#         else:\n",
    "#             # In this case the word was not there at all \n",
    "#             # We will append these separately later \n",
    "#             missing = 1\n",
    "\n",
    "# zygote_pronunciation_tuple = [(\"zygote\", ps, root_ret, missing)]\n",
    "\n",
    "# # Output this to a data frame and then a csv \n",
    "# df = pd.DataFrame(zygote_pronunciation_tuple, columns = ['Word', 'Pronunciation', 'Root Word Returned', 'Missing'])\n",
    "# df.to_csv(\"temp/cambridge_ipas_step5.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did the above with separate data frames to minimize the opportunity for error (and thus work lost). Now, re-read the data frames into a dict. We will iterate through this dict to make some final adjustments to the pronunciations and then output the completed result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO handle four columns now\n",
    "# THIS WILL BE UPDATES AFTER THE FOUR CSVs are GENERATED.\n",
    "# Load in all of the temporary dataframes (each of the four steps) and concatenate them.\n",
    "\n",
    "# Iterate over the CSV files\n",
    "for i in range(1, 5):\n",
    "    # Load the data frame from the CSV file\n",
    "    df = pd.read_csv(f'temp/cambridge_ipas_step{i}.csv')\n",
    "    \n",
    "    # Convert the data frame to a dictionary and update the combined dictionary\n",
    "    all_cambridge_ipas.update(dict(zip(df['Word'], [df['Pronunciation'], df['Root Word Returned'], df['Missing']])))\n",
    "\n",
    "# Verify the length\n",
    "len(all_cambridge_ipas.keys())\n",
    "\n",
    "# Note this length is very different because even many words in the trimmed dictionary are not present in the Cambridge dictionary! We will get a file of these below.\n",
    "# Once done with updates actually this length should be the same "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By inspection it also turns out there are several other characters present in many of the pronunciations that are not a part of the actual pronunciation. We remove all of these as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through all words in the resultant dictionary.\n",
    "# Remove the following characters: ˈ · ː - ˌ with empty string\n",
    "# Also notice for some reason Cambridge dictionary does not have proper \"r\" as \"ɹ\" so we\n",
    "# replace this too\n",
    "# and \"t̬\" should just be \"t\"\n",
    "# finally, any instance of \"e\" should be replaced with \"ɛ\" so long as it is not followed by an \"ɪ\"\n",
    "# as that corresponds to a different phoneme\n",
    "for w, data in all_cambridge_ipas.items():\n",
    "    all_cambridge_ipas[w] = re.sub(r'e(?!ɪ)', 'ɛ', data[0].replace(\"ˈ\",\"\").replace(\"·\",\"\").replace(\"ː\",\"\").replace(\"-\",\"\").replace(\"ˌ\",\"\").replace(\",\",\"\").replace(\"r\",\"ɹ\").replace(\"t̬\",\"t\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to artificially change the pronunciation for \"a\" by inspection and also add the pronunciation for \"i\"\n",
    "all_cambridge_ipas['a'] = \"ɛɪ\"\n",
    "all_cambridge_ipas['i'] = \"aɪ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, output the result to a csv\n",
    "res = []\n",
    "\n",
    "for w, data in all_cambridge_ipas.items():\n",
    "    res.append((w,data[0], data[1], data[2]))\n",
    "\n",
    "df = pd.DataFrame(res, columns=['Word', 'Pronunciation', 'Root Word Returned', 'Missing'])\n",
    "df.to_csv(\"cambridge_ipas.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
